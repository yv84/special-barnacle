apiVersion: apps/v1
kind: StatefulSet
metadata:
  annotations:
    kompose.cmd: kompose convert --file docker-compose-kafka.yaml
    kompose.version: 1.17.0 (a74acad)
  creationTimestamp: null
  labels:
    io.kompose.service: kafka1
  name: kafka1
  namespace: sbarnacle-kafka
spec:
  replicas: 1
  serviceName: kafka1
  selector:
    matchLabels:
      app: kafka1
  template:
    metadata:
      creationTimestamp: null
      labels:
        app: kafka1
    spec:
      containers:
      - env:
        - name: CONFLUENT_METRICS_ENABLE
          value: "true"
        - name: CONFLUENT_METRICS_REPORTER_BOOTSTRAP_SERVERS
          value: kafka1-0.kafka1.sbarnacle-kafka.svc.cluster.local:19092
        - name: CONFLUENT_METRICS_REPORTER_TOPIC_REPLICAS
          value: "1"
        - name: CONFLUENT_METRICS_REPORTER_ZOOKEEPER_CONNECT
          value: zoo1-0.zoo1.sbarnacle-kafka.svc.cluster.local:2181
        - name: CONFLUENT_SUPPORT_CUSTOMER_ID
          value: anonymous
        - name: KAFKA_LISTENERS
          value: INTERNAL_PLAINTEXT://0.0.0.0:9092,EXTERNAL_PLAINTEXT_1://0.0.0.0:9093,EXTERNAL_PLAINTEXT_2://0.0.0.0:9094
        - name: KAFKA_ADVERTISED_LISTENERS
          value: "INTERNAL_PLAINTEXT://localhost:9092,EXTERNAL_PLAINTEXT_1://192.168.100.141:30168,EXTERNAL_PLAINTEXT_2://kafka1-0.kafka1.sbarnacle-kafka.svc.cluster.local:9094"
          # EXTERNAL_PLAINTEXT_1 - outside kube, EXTERNAL_PLAINTEXT_2 - inside kube
          # 192.168.100.141:30168 - хардкод для доступа из вне, пока не понятно как избавится от хардкода зависимости на Service IP:NodePort 192.168.100.141:30168
          # 
          # NAME             TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)                                        AGE
          # service/kafka1   NodePort    10.98.161.41   <none>        9092:32531/TCP,9093:30168/TCP,9094:32692/TCP   31h
          # service/zoo1     ClusterIP   None           <none>        2181/TCP,2888/TCP,3888/TCP                     31h
          # 
          # enp0s3: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500
          #     inet 192.168.100.141  netmask 255.255.255.0  broadcast 192.168.100.255
          #value: INTERNAL_PLAINTEXT://kafka1-0.kafka1.sbarnacle-kafka.svc.cluster.local:19092,EXTERNAL_PLAINTEXT://127.0.0.1:9092
        - name: KAFKA_AUTO_CREATE_TOPICS_ENABLE
          value: "true"
        - name: KAFKA_BROKER_ID
          value: "1"
        - name: KAFKA_INTER_BROKER_LISTENER_NAME
          value: INTERNAL_PLAINTEXT
        - name: KAFKA_LISTENER_SECURITY_PROTOCOL_MAP
          value: INTERNAL_PLAINTEXT:PLAINTEXT,EXTERNAL_PLAINTEXT_1:PLAINTEXT,EXTERNAL_PLAINTEXT_2:PLAINTEXT
        - name: KAFKA_LOG4J_LOGGERS
          value: kafka.controller=DEBUG,kafka.producer.async.DefaultEventHandler=DEBUG,state.change.logger=DEBUG
        - name: KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR
          value: "1"
        - name: KAFKA_ZOOKEEPER_CONNECT
          value: zoo1-0.zoo1.sbarnacle-kafka.svc.cluster.local:2181
        image: confluentinc/cp-kafka:5.0.1
        name: kafka1
        ports:
        - containerPort: 9092
        - containerPort: 9093
        resources:
          requests:
            cpu: 50m
            memory: 100Mi
          #limits:
          #  memory: 600Mi
        readinessProbe:
          tcpSocket:
            port: 9092
          timeoutSeconds: 5
          #exec:
          #  command:
          #  - sh
          #  - -c
          #  - "/opt/kafka/bin/kafka-broker-api-versions.sh --bootstrap-server=localhost:9092"
        volumeMounts:
        - name: config
          mountPath: /etc/kafka
        - name: data
          mountPath: /var/lib/kafka/data
        - name: extensions
          mountPath: /opt/kafka/libs/extensions
      hostname: kafka1
      restartPolicy: Always
      volumes:
      - name: data
        persistentVolumeClaim:
          claimName: kafka1-claim0
      - name: config
        emptyDir: {}
      - name: extensions
        emptyDir: {}

